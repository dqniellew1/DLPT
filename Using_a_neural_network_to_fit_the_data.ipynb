{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using a neural network to fit the data.ipynb",
      "provenance": [],
      "mount_file_id": "1SGOhS22e5n7QDe0xNkxULtHg398aBMut",
      "authorship_tag": "ABX9TyPcPRh0NTabYXdYHHVBJsnl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dqniellew1/DLPT/blob/master/Using_a_neural_network_to_fit_the_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_99BhUe6KWaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_dir = 'drive/My Drive/dlwpt-code/data/'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oVa1Z-8Kfoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9QLBJpwMOoY",
        "colab_type": "text"
      },
      "source": [
        "Basic building block of the complicated functions that make up a neural networks are `neurons`. It consists of a linear transformation of the input and the application of a fixed non-linear function.\n",
        "\n",
        "Mathematically: `o = f(w * x + b)`\n",
        "- o for output\n",
        "- f for activation function\n",
        "- w for weights (can be a single scalar of matrix)\n",
        "- x for inputs (is a scalar or vector)\n",
        "- b for bias / offset\n",
        "\n",
        "**\\*the dimensionality of the inputs and weights must match**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od-Vm9zePE5b",
        "colab_type": "text"
      },
      "source": [
        "Generalities about activation functions\n",
        "- are non-linear. The non-linearity allows the overall network to approximate more complex functions.\n",
        "- are differentiable, so that gradients can be computed through them, *with exceptions\n",
        "\n",
        "Without those, the network falls back to being a complicated polynomial or becomes difficult to train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNVeuYIrY-XD",
        "colab_type": "text"
      },
      "source": [
        "*Code from chapter 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STyXdKwfZGGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c).unsqueeze(1) # temperatures in Celsius\n",
        "t_u = torch.tensor(t_u).unsqueeze(1) # Unknown units"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZWIfpdyY-CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9y9pGCEZR4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d310373-edbe-4278-f227-dd5ad127f426"
      },
      "source": [
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "train_indices, val_indices"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10,  6,  7,  8,  0,  3,  1,  2,  4]), tensor([5, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQTvQ60PZR3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build training and validation set \n",
        "train_t_u = t_u[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_c = t_c[val_indices]\n",
        "\n",
        "# scale our data\n",
        "train_t_un = 0.1 * train_t_u\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI8SNSTsQdE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pib2kTXbYicb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "df1b2a7a-b583-4d89-ca3e-92049ea9f5af"
      },
      "source": [
        "# nn.Linear is a subclass of nn.Module\n",
        "# Linear have their own `__call__` method, therefore we can call it like a function\n",
        "linear_model = nn.Linear(1, 1)\n",
        "linear_model(val_t_un)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.3975],\n",
              "        [-4.1081]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1fp_2DFYqMR",
        "colab_type": "text"
      },
      "source": [
        "`y = model(x)` do this\n",
        "\n",
        "`y = model.forward(x)` dont do this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C6nB2OVazyd",
        "colab_type": "text"
      },
      "source": [
        "The constructor to `nn.Linear` accepts three arguments:\n",
        "1. the number of input features\n",
        "2. the number of output features\n",
        "3. Whether the linear model includes a bias or not (defaults to true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV_4jwPFbXCt",
        "colab_type": "text"
      },
      "source": [
        "\\* The number of features in our case refers to the size of the input and the output tensor for the module.\n",
        "\n",
        "If we used both temperature and barometric pressure in input, for instance, we would have two features in input and one feature in output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGOE3wusb4dK",
        "colab_type": "text"
      },
      "source": [
        "Above we have an instance of `nn.Linear` with one input and one output feature. That only requires one weight and one bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX4825_ScYup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eda45aea-ffbe-43bc-f835-ae16d4d29002"
      },
      "source": [
        "linear_model.weight"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.6180]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0jSd6ofcbnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "118fa923-7bd3-4da2-f6f8-c480cd0f6669"
      },
      "source": [
        "linear_model.bias"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.3756], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRvQOgY-ceu-",
        "colab_type": "text"
      },
      "source": [
        "We can call the module with some inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r09pLiO9cxCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41f50e8d-5b6b-422d-ab3a-a325d80d7e38"
      },
      "source": [
        "x = torch.ones(1)\n",
        "linear_model(x)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9936], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-c0Rx3hc4OD",
        "colab_type": "text"
      },
      "source": [
        "Although PyTorch let us get away with it, we didn't actually provide an input with the right dimensionality. We have a model that takes one input and produces one output, but PyTorch `nn.Module` and its subclasses are designed to do so on multiple samples at the same time. To accomodate multiple samples, modules expect the **zeroth dimension of the input to be the number of samples in the batch**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFfZKpDsdbYl",
        "colab_type": "text"
      },
      "source": [
        "Any module in `nn` is writtern to produce outputs for a batch of multiple inputs at the same time. Thus, assuming we need to run `nn.Linear` on 10 samples, we can create an input tensor of size `B x N_inputs`, where `B` is the size of the batch and `N_inputs` the number of input features, and run it once through the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpipLzNLd6q7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "acccb0d3-0687-4d09-84e7-e3938fd2c028"
      },
      "source": [
        "x = torch.ones(10, 1) # 10 batches, of 1 input\n",
        "linear_model(x)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9936],\n",
              "        [-0.9936],\n",
              "        [-0.9936],\n",
              "        [-0.9936],\n",
              "        [-0.9936],\n",
              "        [-0.9936],\n",
              "        [-0.9936],\n",
              "        [-0.9936],\n",
              "        [-0.9936],\n",
              "        [-0.9936]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRsF_tXWeAqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vifcj_3DfoLe",
        "colab_type": "text"
      },
      "source": [
        "Let's update our training code.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWf2X2HJgDvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. replace our handmade model with nn.Linear(1,1)\n",
        "linear_model = nn.Linear(1, 1)\n",
        "# 2. pass the linear model parameters to the optimizer\n",
        "optimizer = optim.SGD(\n",
        "    linear_model.parameters(), # all the `w` and `b`'s of the model\n",
        "    lr = 1e-2)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dsu1cypgbF3",
        "colab_type": "text"
      },
      "source": [
        "Earlier it was our responsibility to create parameters and pass them as first argument to `optim.SGD`. Now we can just ask any `nn.Module` for a list of parameters owned by it. or any of its submodules using the `paramters` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3FdW92ygv4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "693e574a-bb1a-4cc2-e56d-769c1b1accc9"
      },
      "source": [
        "linear_model.parameters()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7fa6597adba0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FtLHG7Pgxhr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "28775d2c-0d2c-417a-e8c9-18aa0510f196"
      },
      "source": [
        "list(linear_model.parameters())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.1122]], requires_grad=True), Parameter containing:\n",
              " tensor([0.9529], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTYyIIeegzcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    t_p_train = model(t_u_train)\n",
        "    loss_train = loss_fn(t_p_train , t_c_train)\n",
        "\n",
        "    t_p_val = model(t_u_val)\n",
        "    loss_val = loss_fn(t_p_val, t_c_val)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch == 1 or epoch % 1000 == 0:\n",
        "      print('Epoch {}, Training loss {}, Validation loss {}'.format(\n",
        "          epoch, float(loss_train), float(loss_val)))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxm3jGZiiNi-",
        "colab_type": "text"
      },
      "source": [
        "The training loop does not change at all from our hand made example, **except that now we don't pass `params` explicitly to `model`** since the model itself holds its `Parameters` internally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzO34gKift_",
        "colab_type": "text"
      },
      "source": [
        "We can leverage loss functions from `torch.nn`. `nn` comes with several common loss functions amoong which `nn.MSELoss` which is exactly what we defined earlier as our `loss_fn`. Loss functions in `nn` are still subclasses of `nn.Module`, so we will create an instance and call it as a function. In our case, we got rid of the hand-written `loss_fn` and replace it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsUvtDcGjGie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "49ed70b7-6c2a-4ee7-93bd-6356d408cec1"
      },
      "source": [
        "linear_model = nn.Linear(1, 1) # applies an affine transformation to its input via model parameters\n",
        "optimizer = optim.SGD(\n",
        "    linear_model.parameters(),\n",
        "    lr=1e-2)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 3000,\n",
        "    optimizer = optimizer,\n",
        "    model = linear_model,\n",
        "    loss_fn = nn.MSELoss(), # create an instance and call it as a function\n",
        "    t_u_train = train_t_un,\n",
        "    t_u_val = val_t_un,\n",
        "    t_c_train = train_t_c,\n",
        "    t_c_val = val_t_c)\n",
        "\n",
        "print()\n",
        "print(linear_model.weight)\n",
        "print(linear_model.bias)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss 178.0482635498047, Validation loss 93.85664367675781\n",
            "Epoch 1000, Training loss 3.456367015838623, Validation loss 4.09751033782959\n",
            "Epoch 2000, Training loss 2.8643579483032227, Validation loss 3.976336717605591\n",
            "Epoch 3000, Training loss 2.854109048843384, Validation loss 3.9680535793304443\n",
            "\n",
            "Parameter containing:\n",
            "tensor([[5.4238]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-17.2474], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYHiULx_jsCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}