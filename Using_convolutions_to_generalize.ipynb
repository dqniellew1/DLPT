{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using convolutions to generalize.ipynb",
      "provenance": [],
      "mount_file_id": "1CkVi73x_T9YI_RHVdh5aZJy-dYEn4C5c",
      "authorship_tag": "ABX9TyNrVoDQc2/1OaXAgL9yzC9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eaa5d75512c04e828df5c7272f4afad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2dbda1de4ea14cec88f098b0ce258825",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f55e957795f46aea6035e7a0045ad1c",
              "IPY_MODEL_429e0cc9595f415895245f54bded7f20"
            ]
          }
        },
        "2dbda1de4ea14cec88f098b0ce258825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f55e957795f46aea6035e7a0045ad1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7905c27f02dd4690980a267de88d8d0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bce62753ecce4a3dbab8b9cb3426a163"
          }
        },
        "429e0cc9595f415895245f54bded7f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81518f5e026f4b58b1e705bdcd182ee1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 51338093.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_623849fef33b4b76875dee3ce034d4be"
          }
        },
        "7905c27f02dd4690980a267de88d8d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bce62753ecce4a3dbab8b9cb3426a163": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81518f5e026f4b58b1e705bdcd182ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "623849fef33b4b76875dee3ce034d4be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dqniellew1/DLPT/blob/master/Using_convolutions_to_generalize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9T3pQNnL7Ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_dir = 'drive/My Drive/dlwpt-code/data/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph0WLgkvL-KU",
        "colab_type": "text"
      },
      "source": [
        "Taking a 1D view of our input image and multiplying it with a `n_output_features x n_input_features` weight matrix, as done in `nn.Linear`, means taking all pixels in the image, and for each channel computing a weighted sum of all pixels multiplied by a set of weights, one per output feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHdHZ-Na86hS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca6ae873-5ef4-4d91-a14c-1a81c679c368"
      },
      "source": [
        "%matplotlib inline \n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa029667250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2heZVKv4Qw49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acwAHrZSQzkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "eaa5d75512c04e828df5c7272f4afad2",
            "2dbda1de4ea14cec88f098b0ce258825",
            "0f55e957795f46aea6035e7a0045ad1c",
            "429e0cc9595f415895245f54bded7f20",
            "7905c27f02dd4690980a267de88d8d0f",
            "bce62753ecce4a3dbab8b9cb3426a163",
            "81518f5e026f4b58b1e705bdcd182ee1",
            "623849fef33b4b76875dee3ce034d4be"
          ]
        },
        "outputId": "5f5ca83f-970b-4e24-e6bd-dc1f1a3486cd"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                                                         transforms.ToTensor(),\n",
        "                                                         transforms.Normalize(\n",
        "                                                             (0.4915, 0.4823, 0.4468),\n",
        "                                                             (0.2470, 0.2435, 0.2616))\n",
        "                                                         ]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaa5d75512c04e828df5c7272f4afad2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data-unversioned/p1ch6/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfcpy1TkROuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
        "                               transform=transforms.Compose([\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                                                   (0.2470, 0.2435, 0.2616))\n",
        "                              ]))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMcmHmVXRc_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map = {0:1, 2:1}\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7qRa8T9D2S2",
        "colab_type": "text"
      },
      "source": [
        "# Convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV3bQ3GsO8S-",
        "colab_type": "text"
      },
      "source": [
        "`nn.Conv1d` for time series, `nn.Conv2d` for images and `nn.Conv3d` for volumes or videos.\n",
        "\n",
        "The arguments we provide to `nn.Conv2d` are the:\n",
        "1. The number of input features (or channels, since we are dealing with so-called multi-channel images, i.e. more than one value per pixel)\n",
        "2. The number of output features (arbitrary number, the more channels in the output image, the more the capacity of the network)\n",
        "3. The size of the kernel\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzaFtlFNPrNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e113319f-55f0-4d0c-9ddb-5e0e45e81723"
      },
      "source": [
        "conv = nn.Conv2d(3, 16, kernel_size=3)\n",
        "conv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqTcXjlrQEQF",
        "colab_type": "text"
      },
      "source": [
        "We expect the weight tensor to be sized `n_input_channels x 3 x 3 x n_output_channels`. The bias is just a constant value we add to each channel of the output image.\n",
        "\n",
        "\\* weights are initialized randomly\n",
        "\n",
        "**As usual we need to add the zero-th batch dimension with unsqueeze** if we want to call the `conv` module with one input image. `nn.Conv2d` expects `B x C x H x W`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkrnnzkSPv_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aa78316-04be-4b7d-c92c-81b9923dd977"
      },
      "source": [
        "conv.weight.shape, conv.bias.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 3, 3, 3]), torch.Size([16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK6YCWphP4Ue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c67a1353-1633-48b6-9eb0-eec9ae9a3c5b"
      },
      "source": [
        "img, _ = cifar2[0]\n",
        "output = conv(img.unsqueeze(0))\n",
        "img.unsqueeze(0).shape, output.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M-U7tZkSffd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "877b1d5d-701d-4665-c398-03d112cfa9ab"
      },
      "source": [
        "plt.imshow(output[0,0].detach(), cmap='gray')\n",
        "plt.show()\n",
        "# Bird after a random convolution treatment"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa2SWeq4SrS_",
        "colab_type": "text"
      },
      "source": [
        "The output size is slightly less because it is a side effect of deciding what to do at the boundary of the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfFK_RdXTy0L",
        "colab_type": "text"
      },
      "source": [
        "To preserve image size, PyTorch gives us the possibility of padding the image, creating ghost pixels around the border that value zero as far as the convolution is concerned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-Shp8w7UOuU",
        "colab_type": "text"
      },
      "source": [
        "Specifying `padding=1` when `kernel_size=3` means that now `i00` has an extra set of neighbours above and left, so that an output of the convolution can be computed even in the corner of our original image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnxVl1lPUimx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b40260e7-3ce5-4cc9-a6e1-01764d930188"
      },
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
        "output = conv(img.unsqueeze(0))\n",
        "img.unsqueeze(0).shape, output.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 1, 32, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsvuHQAXUub8",
        "colab_type": "text"
      },
      "source": [
        "\\* the size of `weight` and `bias` dont change whether padding is used or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmD23APjU2yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# play with convolution setting; weights by hand\n",
        "with torch.no_grad():\n",
        "  conv.bias.zero_() # zero out bias to remove any confounding factor\n",
        "\n",
        "with torch.no_grad():\n",
        "  conv.weight.fill_(1.0 / 9.0)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STcDRDoGVWV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "547b883d-7158-4159-f6db-e3e3a72f6ea4"
      },
      "source": [
        "# See the results in the output image\n",
        "output = conv(img.unsqueeze(0))\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.show()\n",
        "# bird, this time blurred thanks to a constant convolution kernel."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxkqKjzpVy5M",
        "colab_type": "text"
      },
      "source": [
        "Every pixel of the output is the average of a neighborhood of the input, so output pixels of the output will be correlated and change more smoothly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXt3K-sWZx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can try something different\n",
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
        "\n",
        "with torch.no_grad():\n",
        "  conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0]])\n",
        "  conv.bias.zero_()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAXDV5FmWogb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "9571e685-c3bb-45a8-9030-66ebd01245bb"
      },
      "source": [
        "output = conv(img.unsqueeze(0))\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.show()\n",
        "# Vertical edges throughout our bird because of hand-crafted kernel"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwIhMfXOW1kz",
        "colab_type": "text"
      },
      "source": [
        "## Depth and pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huQCAKDIacBI",
        "colab_type": "text"
      },
      "source": [
        "If we wish to downsample our image by half, we'll want to use a size of 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIuTchTSeE8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ef0551c-9087-4cdd-9cb7-9a9d05de1891"
      },
      "source": [
        "pool = nn.MaxPool2d(2)\n",
        "output = pool(img.unsqueeze(0))\n",
        "\n",
        "img.unsqueeze(0).shape, output.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4VwbjBeeMLg",
        "colab_type": "text"
      },
      "source": [
        "Proceed to building our convolutional neural network for detecting birds and planes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3kmtKWieYys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "    nn.Tanh(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
        "    nn.Tanh(),\n",
        "    nn.MaxPool2d(2),\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx_374mvenbK",
        "colab_type": "text"
      },
      "source": [
        "Gone from 3 RGB channels to 16, thereby giving the network a chance to generate 16 independent features that will operate to hopefully discriminate low-level features of birds and airplanes. \n",
        "\n",
        "After the activation is applied, the 16-channel 32x32 image will be pooled to a 16-channel 16x16 image. \n",
        "\n",
        "At this point, the downsampled image will undergo another convolution that will generate a 8-channel 16x16 output, which again after the activation, will be pooled to a 8-channel 8x8 output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MEpuJGgfSDB",
        "colab_type": "text"
      },
      "source": [
        "After the input image has been reduced to a set of 8x8 features, we expect some output of probabilities, so that we can feed our negative log likelihood. \n",
        "\n",
        "However, probabilities are a pair of numbers in a 1D vector (1 for bird, 1 for airplane, while we are still dealing with multi-channel 2D features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hWy94u6fzYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn our 8-channel 8x8 image into a 1D vector \n",
        "# Complete our network with a set of fully connected layers.\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "    nn.Tanh(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
        "    nn.Tanh(),\n",
        "    nn.MaxPool2d(2),\n",
        "    # ... Missing something important?\n",
        "    nn.Linear(8 * 8 * 8, 32),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(32, 2))\n",
        "# Linear layer is dependent on the expected size of the MaxPool2d output\n",
        "# i.e. 8 * 8 * 8 = 512"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faiClP3OgT4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4eef05cb-02a6-4302-b4cf-3c86be0ebf4b"
      },
      "source": [
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x78-X5XgsbK",
        "colab_type": "text"
      },
      "source": [
        "Reasonable! In order to increase the capacity of the model, we could\n",
        "1. increase the number of output channels for the conv layers (which would lead to the linear layer increasing in size as well)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di1QZ0sMhFl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "6645941c-7382-4b2a-b296-b2d1b412024e"
      },
      "source": [
        "model(img.unsqueeze(0))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-9c784fd7714c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [64 x 8], m2: [512 x 32] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFx1p_YUhKpD",
        "colab_type": "text"
      },
      "source": [
        "What is missing there is the **reshaping step** from a 8-channel 8x8 image to a 512-element, 1D vector.\n",
        "\n",
        "We could use `view` on the output of the last `nn.MaxPool2d` but we dont have visibility of output of each module when we use `nn.Sequential`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiW0_iJNhiet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}